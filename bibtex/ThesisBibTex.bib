% Encoding: UTF-8

@Article{Benczur2015,
  author    = {Andr{\'{a}}s A. Bencz{\'{u}}r and David R. Karger},
  title     = {{R}andomized {A}pproximation {S}chemes for {C}uts and {F}lows in {C}apacitated {G}raphs},
  journal   = {{SIAM} Journal on Computing},
  year      = {2015},
  volume    = {44},
  number    = {2},
  pages     = {290--319},
  month     = {jan},
  abstract  = {We describe random sampling techniques for approximately solving problems that involve cuts and flows in graphs. We give a near-linear-time randomized combinatorial construction that transforms any graph on n vertices into an O(n log n)-edge graph on the same vertices whose cuts have approximately the same value as the original graph’s. In this new graph, for example, we can run the
O˜(m3/2)-time maximum flow algorithm of Goldberg and Rao to find an s-t minimum cut in O˜(n3/2) time. This corresponds to a (1 + ǫ)-times minimum s-t cut in the original graph. A
related approach leads to a randomized divide-and-conquer algorithm producing an approximately maximum flow in
√ O˜(m n) time. Our algorithm can also be used to improve the running time of sparsest cut approximation algorithms from ˜O(mn) to O˜(n2), and to accelerate several other recent
cut and flow algorithms. Our algorithms are based on a general theorem analyzing the concentration of random graphs’ cut values near their expectations. Our work draws only on elementary probability
and graph theory.},
  comment   = {approximation of graphs via sparse graphs to approximate cut and flow values via randomized sampling, divide and conquer variant with limit on probability used for sampling},
  doi       = {10.1137/070705970},
  file      = {:Benczur2015, Karger, RANDOMIZED APPROXIMATION SCHEMES FOR CUTS AND Flows In Capacitated Graphs.pdf:PDF},
  keywords  = {edge strength, edge connectivity, strong edge connectivity, rank3},
  publisher = {Society for Industrial {\&} Applied Mathematics ({SIAM})},
}

@Article{Rubinstein2017,
  author      = {Aviad Rubinstein and Tselil Schramm and S. Matthew Weinberg},
  title       = {Computing exact minimum cuts without knowing the graph},
  journal     = {no idea},
  year        = {2016},
  abstract    = {We give query-efficient algorithms for the global min-cut and the s-t cut problem in unweighted, undirected graphs. Our oracle model is inspired by the submodular function minimization problem: on query $S \subset V$, the oracle returns the size of the cut between $S$ and $V \setminus S$. We provide algorithms computing an exact minimum $s$-$t$ cut in $G$ with $\tilde{O}(n^{5/3})$ queries, and computing an exact global minimum cut of $G$ with only $\tilde{O}(n)$ queries (while learning the graph requires $\tilde{\Theta}(n^2)$ queries).},
  comment     = {based on subsampling min cuts are computed with high probability, running times above linear, but subquadratic},
  date        = {2017-11-08},
  doi         = {10.1109/focs.2016.35},
  eprint      = {http://arxiv.org/abs/1711.03165v2},
  eprintclass = {cs.DS},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1711.03165v2:PDF;:Rubinstein2018-Computing Exact Minimum Cuts Without Knowing the Graph.pdf:PDF},
  keywords    = {cs.DS, rank2},
}

@Article{Thorup1999,
  author    = {Mikkel Thorup},
  title     = {Decremental Dynamic Connectivity},
  journal   = {Journal of Algorithms},
  year      = {1999},
  volume    = {33},
  number    = {2},
  pages     = {229--243},
  month     = {nov},
  comment   = {only deletions are considered, only considers unweighted connectivity (i.e. whether the graph or two vertices are connected)},
  doi       = {10.1006/jagm.1999.1033},
  file      = {:Thorup1999-Decremental Dynamic Connectivity.pdf:PDF},
  keywords  = {rank2},
  publisher = {Elsevier {BV}},
}

@Article{Avin2015,
  author      = {Chen Avin and Marcin Bienkowski and Andreas Loukas and Maciej Pacut and Stefan Schmid},
  journal     = {{arXiv preprint arXiv:1511.02074v5}},
  title       = {{D}ynamic {B}alanced {G}raph {P}artitioning},
  year        = {2015},
  abstract    = {This paper initiates the study of the classic balanced graph partitioning problem from an online perspective: Given an arbitrary sequence of pairwise communication requests between $n$ nodes, with patterns that may change over time, the objective is to service these requests efficiently by partitioning the nodes into $\ell$ clusters, each of size $k$, such that frequently communicating nodes are located in the same cluster. The partitioning can be updated dynamically by migrating nodes between clusters. The goal is to devise online algorithms which jointly minimize the amount of inter-cluster communication and migration cost. The problem features interesting connections to other well-known online problems. For example, scenarios with $\ell=2$ generalize online paging, and scenarios with $k=2$ constitute a novel online variant of maximum matching. We present several lower bounds and algorithms for settings both with and without cluster-size augmentation. In particular, we prove that any deterministic online algorithm has a competitive ratio of at least $k$, even with significant augmentation. Our main algorithmic contributions are an $O(k \log{k})$-competitive deterministic algorithm for the general setting with constant augmentation, and a constant competitive algorithm for the maximum matching variant.},
  date        = {2015-11-06},
  eprint      = {http://arxiv.org/abs/1511.02074v4},
  eprintclass = {cs.DS},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1511.02074v4:PDF;:Avin2015-DynamicBalancedGraphPartitioning.pdf:PDF},
  keywords    = {cs.DS, rank5, clustering, graph partitioning, competitive analysis, cloud computing},
  ranking     = {rank5},
}

@InProceedings{Thorup2000,
  author    = {Mikkel Thorup},
  title     = {Near-optimal fully-dynamic graph connectivity},
  booktitle = {Proceedings of the thirty-second annual {ACM} symposium on Theory of computing - {STOC} {\textquotesingle}00},
  year      = {2000},
  publisher = {{ACM} Press},
  abstract  = {In this paper we present near-optimal bounds for fullydynamic graph connectivity which is the most basic nontrivial fully-dynamic graph problem. Connectivity queries are supported in O(log n/log log log n) time while the updates are supported in O(log n(log log n) 3) expected amortized time. The previous best update time was O((log n)2). Our new bound is only doubly-logarithmic factors from a general cell probe lower bound of f2(log n~ log log n). Our algorithm runs on a pointer machine, and uses only standard AC ° instructions. In our developments we make some comparatively trivial observations improving some deterministic bounds. The space bound of the previous O((log n) ~) connectivity algorithm is improved from O(m + n log n) to O(m). The previous time complexity of fully-dynamic 2-edge and biconnectivity is im-
proved from O((log n) 4) to O((log n) 3 log log n).},
  comment   = {dynamic connectivity based on maintaining a spanning, only answers whether two given vertices are connected},
  doi       = {10.1145/335305.335345},
  file      = {:Thorup2000-Near-optimal fully-dynamic graph connectivity.pdf:PDF},
  keywords  = {rank2},
}

@Article{Hartuv2000,
  author    = {Erez Hartuv and Ron Shamir},
  title     = {A clustering algorithm based on graph connectivity},
  journal   = {Information Processing Letters},
  year      = {2000},
  volume    = {76},
  number    = {4-6},
  pages     = {175--181},
  month     = {dec},
  abstract  = {We have developed a novel algorithm for cluster analysis that is based on graph theoretic techniques. A similarity graph is defined and clusters in that graph correspond to highly connected subgraphs. A polynomial algorithm to compute them efficiently is presented. Our algorithm produces a solution with some provably good properties and performs well on simulated
and real data. © 2000 Elsevier Science B.V. All rights reserved.},
  comment   = {clustering based on highly connected subgraphs based on edge connectivity, algorithm based on highly connected subgraph splits graph and recurses.
Might be problematic as highly connected means here that the connectivity is at least n as opposed to at least alpha which we want.
Running time:  O(2N * f(n,m)), 
where N is the number of clusters found and f(n,m) is the time complexity of computing a minimum cut in a graph with n vertices and m edges},
  doi       = {10.1016/s0020-0190(00)00142-3},
  file      = {:Hartuv2000-A clustering algorithm based on graph connectivity.pdf:PDF},
  keywords  = {Algorithms; Clustering; Minimum cut; Graph connectivity; Diameter, rank3},
  publisher = {Elsevier {BV}},
}

@Article{Henzinger1998,
  author    = {M. R. Henzinger and M. L. Fredman},
  title     = {{L}ower {B}ounds for {F}ully {D}ynamic {C}onnectivity {P}roblems in {G}raphs},
  journal   = {Algorithmica},
  year      = {1998},
  volume    = {22},
  number    = {3},
  pages     = {351--362},
  month     = {nov},
  abstract  = {We prove lower bounds on the complexity of maintaining fully dynamic k-edge or k-vertex connectivity in plane graphs and in (k − 1)-vertex connected graphs. We show an amortized lower bound of (log n/k(log log n +log b)) per edge insertion, deletion, or query operation in the cell probe model, where b is the word size of the machine and n is the number ofvertices in G. We also show an amortized lower bound of (log n/(log log n + log b)) per operation for fully dynamic planarity testing in embedded graphs. These
are the first lower bounds for fully dynamic connectivity problems.},
  comment   = {Focus on unweighted graphs, partly plane or k-1 vertex connected, lower bounds by reductions to prefix sum problems

reductions: helpful parity prefix sum problem to the fully dynamic planarity testing problem; helpful parity prefix problem to  fully dynamic problem and a current graph G with at least n + 1},
  doi       = {10.1007/pl00009228},
  file      = {:Henzinger1998-Fredman1998_Article_LowerBoundsForFullyDynamicConn.pdf:PDF},
  keywords  = {Dynamic planarity testing, Dynamic connectivity testing, Lower bounds, Cell probe model, rank2},
  publisher = {Springer Science and Business Media {LLC}},
}

@PhdThesis{Duan2011,
  author   = {Ran Duan},
  title    = {{A}lgorithms and {D}ynamic {D}ata {S}tructures for {B}asic {G}raph {O}ptimization {P}roblems},
  school   = {The University of Michigan},
  year     = {2011},
  comment  = {Unweighted only, uses tree structures and hierarchy based on node degree, starting on page 108},
  file     = {:Duan2011-Algorithms and Dynamic Data Structures for Basic Graph Optimization Problems_.pdf:PDF},
  keywords = {rank2},
  url      = {https://deepblue.lib.umich.edu/bitstream/handle/2027.42/89641/duanran_1.pdf},
}

@Article{Wulff-Nilsen2012,
  author      = {Christian Wulff-Nilsen},
  title       = {{F}aster {D}eterministic {F}ully-{D}ynamic {G}raph {C}onnectivity},
  journal     = {no idea},
  year        = {2012},
  abstract    = {We give new deterministic bounds for fully-dynamic graph connectivity. Our data structure supports updates (edge insertions/deletions) in $O(\log^2n/\log\log n)$ amortized time and connectivity queries in $O(\log n/\log\log n)$ worst-case time, where $n$ is the number of vertices of the graph. This improves the deterministic data structures of Holm, de Lichtenberg, and Thorup (STOC 1998, J.ACM 2001) and Thorup (STOC 2000) which both have $O(\log^2n)$ amortized update time and $O(\log n/\log\log n)$ worst-case query time. Our model of computation is the same as that of Thorup, i.e., a pointer machine with standard $AC^0$ instructions.},
  comment     = {does not consider weighted cuts, only whether two nodes are connected},
  date        = {2012-09-25},
  eprint      = {http://arxiv.org/abs/1209.5608v1},
  eprintclass = {cs.DS},
  eprinttype  = {arXiv},
  file        = {:Wulff-Nilsen2012 - Faster Deterministic Fully Dynamic Graph Connectivity.pdf:PDF;:Wulff-Nilsen-Faster Deterministic Fully-Dynamic Graph Connectivity.pdf:PDF;:Wulff-Nilsen2012 - Faster Deterministic Fully Dynamic Graph Connectivity.pdf:PDF},
  keywords    = {cs.DS, cs.DM, G.2.2, rank2},
}

@InProceedings{Ahn2012,
  author    = {Kook Jin Ahn and Sudipto Guha and Andrew McGregor},
  title     = {Graph sketches},
  booktitle = {Proceedings of the 31st symposium on Principles of Database Systems - {PODS} {\textquotesingle}12},
  year      = {2012},
  publisher = {{ACM} Press},
  abstract  = {When processing massive data sets, a core task is to construct synopses of the data. To be useful, a synopsis data structure should be
easy to construct while also yielding good approximations of the relevant properties of the data set. A particularly useful class of synopses are sketches, i.e., those based on linear projections of the data. These are applicable in many models including various parallel, stream, and compressed sensing settings. A rich body of analytic and empirical work exists for sketching numerical data such as the frequencies of a set of entities. Our work investigates graph sketching where the graphs of interest encode the relationships between these entities. The main challenge is to capture this richer structure and build the necessary synopses with only linear measurements. In this paper we consider properties of graphs including the size
of the cuts, the distances between nodes, and the prevalence of dense sub-graphs. Our main result is a sketch-based sparsifier construction: we show that
O˜(n−2) random linear projections of a
graph on n nodes suffice to (1 + ) approximate all cut values. Similarly, we show that O(−2) linear projections suffice for (additively) approximating the fraction of induced sub-graphs that match a given pattern such as a small clique. Finally, for distance estimation we present sketch-based spanner constructions. In this last result the sketches are adaptive, i.e., the linear projections are performed in a small number of batches where each projection may be chosen dependent on the outcome of earlier sketches. All of the above results immediately give rise to data stream algorithms that also apply to dynamic graph streams where edges are both inserted and deleted. The non-adaptive sketches, such as those for sparsification and subgraphs, give us single-pass algorithms for distributed data streams with insertion and deletions. The adaptive sketches can be used to analyze MapReduce algorithms that use a
small number of rounds.},
  doi       = {10.1145/2213556.2213560},
  file      = {:Ahn2012-Graph Sketches- Sparsification, Spanners, and Subgraphs.pdf:PDF},
  keywords  = {data streams, graph sketching, sparsification, spanners, subgraphs, rank1},
}

@InCollection{Wu2008,
  author    = {Yongan Wu and Min Li and Zhiping Cai and En Zhu},
  title     = {{A} {D}istributed {A}lgorithm to {A}pproximate {N}ode-{W}eighted {M}inimum $\upalpha$-{C}onnected ({\texttheta},k)-{C}overage in {D}ense {S}ensor {N}etworks},
  booktitle = {Frontiers in Algorithmics},
  publisher = {Springer Berlin Heidelberg},
  year      = {2008},
  pages     = {221--232},
  comment   = {probabilistic model with alpha in (0,1), more about sensor networks than regular graphs},
  doi       = {10.1007/978-3-540-69311-6_24},
  file      = {:Wu2008_Chapter_ADistributedAlgorithmToApproxi.pdf:PDF},
  keywords  = {rank1},
}

@Article{Nagamochi2006,
  author    = {Hiroshi Nagamochi},
  title     = {Sparse connectivity certificates via {MA} orderings in graphs},
  journal   = {Discrete Applied Mathematics},
  year      = {2006},
  volume    = {154},
  number    = {16},
  pages     = {2411--2417},
  month     = {nov},
  doi       = {10.1016/j.dam.2006.04.008},
  file      = {:Nagamochi2006-Sparse connectivity certificates via MA orderings in graphs.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Nutov2011,
  author    = {Zeev Nutov},
  title     = {Approximating directed weighted-degree constrained networks},
  journal   = {Theoretical Computer Science},
  year      = {2011},
  volume    = {412},
  number    = {8-10},
  pages     = {901--912},
  month     = {mar},
  comment   = {uses LP and polytope theory to find an f-connected subgraph in polynomial time (too slow!)},
  doi       = {10.1016/j.tcs.2010.11.043},
  file      = {:Nutov2011 - Approximating Directed Weighted Degree Constrained Networks.pdf:PDF},
  keywords  = {rank2},
  publisher = {Elsevier {BV}},
}

@Article{Henzinger2019,
  author      = {Monika Henzinger and Stefan Neumann and Stefan Schmid},
  title       = {{E}fficient {D}istributed {W}orkload ({R}e-){E}mbedding},
  journal     = {no idea},
  year        = {2019},
  abstract    = {Modern networked systems are increasingly reconfigurable, enabling demand-aware infrastructures whose resources can be adjusted according to the workload they currently serve. Such dynamic adjustments can be exploited to improve network utilization and hence performance, by moving frequently interacting communication partners closer, e.g., collocating them in the same server or datacenter. However, dynamically changing the embedding of workloads is algorithmically challenging: communication patterns are often not known ahead of time, but must be learned. During the learning process, overheads related to unnecessary moves (i.e., re-embeddings) should be minimized. This paper studies a fundamental model which captures the tradeoff between the benefits and costs of dynamically collocating communication partners on $\ell$ servers, in an online manner. Our main contribution is a distributed online algorithm which is asymptotically almost optimal, i.e., almost matches the lower bound (also derived in this paper) on the competitive ratio of any (distributed or centralized) online algorithm. As an application, we show that our algorithm can be used to solve a distributed union find problem in which the sets are stored across multiple servers.},
  comment     = {nice lower bounds, algorithm using partitioning of vertices and small-large rebalancing as well as majority voting
algorithms for the two server case},
  date        = {2019-04-10},
  eprint      = {http://arxiv.org/abs/1904.05474v1},
  eprintclass = {cs.DS},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1904.05474v1:PDF;:Henzinger2019-Efficient Distributed Workload (Re-)Embedding.pdf:PDF},
  keywords    = {cs.DS, cs.DC, cs.NI, rank4},
}

@InCollection{Olver2018,
  author    = {Neil Olver and Kirk Pruhs and Kevin Schewior and Ren{\'{e}} Sitters and Leen Stougie},
  title     = {{T}he {I}tinerant {L}ist {U}pdate {P}roblem},
  booktitle = {Approximation and Online Algorithms},
  publisher = {Springer International Publishing},
  year      = {2018},
  pages     = {310--326},
  doi       = {10.1007/978-3-030-04693-4_19},
  file      = {:Olver2018-ItinerantListUpdate.pdf:PDF},
  keywords  = {rank1},
}

@Unpublished{Schonger2019,
  author   = {Martin Schonger},
  title    = {{A}lgorithm {E}ngineering for {R}epartitioning {D}ynamic {G}raphs},
  note     = {No idea},
  abstract = {With an ever increasing demand for distributed computation comes the need to dynamically collocate frequently communicating parts of the workload. This corresponds to the Balanced RePartitioning (BRP) problem, which is algorithmically challenging as communication patterns are (a) rarely known in advance and (b) can change over time. Previous work has primarily considered theoretical aspects. We study the BRP from an algorithm engineering perspective. To this end, we revisit CREP, identify its bottleneck, and propose to combine it with efficient heuristics. These include the greedy approximation algorithm by Charikar as well as limiting the search for dense substructures to the 2-hop neighborhood of the latest communication request. Furthermore, we use decaying edge weights to model the temporal locality found in real network patterns. In an extensive evaluation we compare our algorithms on production-level and generated traffic traces. The proposed heuristics yield a significant improvement of both partition quality and run time.},
  file     = {:Schonger Thesis - Algorithm Engineering for Repartitioning Dynamic Graphs (2019).pdf:PDF},
  keywords = {rank4},
}

@Article{Benabdellah2019,
  author    = {Abla Chouni Benabdellah and Asmaa Benghabrit and Imane Bouhaddou},
  title     = {A survey of clustering algorithms for an industrial context},
  journal   = {Procedia Computer Science},
  year      = {2019},
  volume    = {148},
  pages     = {291--302},
  abstract  = {different resources and services. Hence, there is an urgent need for a new generation of computational theories and tools to assist humans in extracting useful information from the rapidly growing volumes of digital data. A well-known fundamental task of data mining to extract information is clustering. However, with the modified applications for various domains, several researchers have developed and have provided many clustering algorithms. This complexity makes it difficult for researchers and practitioners to keep up with clustering algorithms development. As a result, finding appropriate algorithms helps significantly to organize information and extract the correct answer from different queries of the databases. In this respect, the aim of this paper is to find the appropriate clustering algorithm for sparse industrial dataset. To achieve this goal, we first present related work that focus on comparing different clustering algorithms over the past twenty years. After that, we provide a categorization of different clustering algorithms found in the literature by matching their properties to the 4V’s challenges of Big data which allow us to select the candidate clustering algorithm. Finally, using internal validity indices, K-means, agglomerative hierarchical, DBSCAN and SOM have been implemented and compared on four datasets. In addition, we highlighted the best performing clustering algorithm that gives us the efficient clusters
Across a wide variety of fields and sp cially for ind strial companies, data are being collected and accumulated at a dramatic pace from many different resources and services. Hence, there is an urgent need for a new generation of computational theories and tools to ass st humans in extracting useful information from the rapidly growing volumes of digital data. A well-known fundamental task of data mining to extract information s cluste ng. However, with the modif ed applications for various domains, several researchers have developed and have provided many clus er ng algorithms. This complexity makes it difficult for esearchers and practitioners to keep up wi h clustering algorithms development. As a result, finding appropriate algorithms helps significantly to organize info mation and extract the correct answer from different queries of th databases. In this respect, the aim of this pape is to ind the appropriate clustering algorithm for sparse industrial dataset. To achieve this goal, we first present rela ed work that focus on comparing different clustering algorithms over the past twenty year . After that,
e provide a categorization
of different clustering algorithms found in the literature by matching their properties to the 4V’s challenges of Big data which allow us to select the candidate clustering algorithm. Finally, u ing internal validity indices, K-means, agglomerative hierarch cal, DBSCAN and SOM have been
implemented and compared on four datasets. In addition, we highlighted the best performing clustering algorithm that gives us the efficient clusters},
  comment   = {No real algorithms, just very general roundup of research papers about clustering},
  doi       = {10.1016/j.procs.2019.01.022},
  file      = {:Benabdellah2019 - A Survey of Clustering Algorithms for an Industrial Context.pdf:PDF},
  keywords  = {rank1},
  publisher = {Elsevier {BV}},
}

@Article{Wu1993,
  author    = {Z. Wu and R. Leahy},
  title     = {An optimal graph theoretic approach to data clustering: theory and its application to image segmentation},
  journal   = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
  year      = {1993},
  volume    = {15},
  number    = {11},
  pages     = {1101--1113},
  comment   = {clustering focused, no apparent bounds},
  doi       = {10.1109/34.244673},
  file      = {:Wu1993 - An Optimal Graph Theoretic Approach to Data Clustering_ Theory and Its Application to Image Segmentation.pdf:PDF},
  keywords  = {rank1},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@InProceedings{Pavana,
  author    = {M. Pavan and M. Pelillo},
  title     = {A new graph-theoretic approach to clustering and segmentation},
  booktitle = {2003 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.},
  year      = {2003},
  publisher = {{IEEE} Comput. Soc},
  abstract  = {We develop a framework for the image segmentation problem based on a new graph-theoretic formulation of clustering. The approach is motivated by the analogies between the intuitive concept ofa cluster and that ofa dominant set ofvertices, a novel notion that generalizes that ofa maximal complete subgraph to edge-weighted graphs. We also establish a correspondence between dominant sets and the extrema ofa quadratic form over the standard simplex, thereby allowing us the use ofcontinuous optimization techniques such as replicator dynamics from evolutionary game theory. Such systems are attractive as can be coded in a few lines of any high-level programming language, can easily be implemented in a parallel network of locally interacting units, and offer the advantage ofbiological plausibility. We present experimental results on real-world images which
show the effectiveness ofthe proposed approach.},
  comment   = {based on combinatorial concept of dominant set, not dynamic or with complexity guarantees},
  doi       = {10.1109/cvpr.2003.1211348},
  file      = {:A New Graph-Theoretic Approach to Clustering and Segmentation.pdf:PDF},
  keywords  = {rank1},
}

@InCollection{Buluc2016,
  author    = {Ayd{\i}n Bulu{\c{c}} and Henning Meyerhenke and Ilya Safro and Peter Sanders and Christian Schulz},
  booktitle = {Algorithm Engineering},
  publisher = {Springer International Publishing},
  title     = {{Recent Advances in Graph Partitioning}},
  year      = {2016},
  pages     = {117--158},
  comment   = {only Graph partitioning, but no info about edge strength/connectivity
might contain some good heuristics for improving algorithms},
  doi       = {10.1007/978-3-319-49487-6_4},
  file      = {:Buluc2016 - Recent Advances in Graph Partitioning.pdf:PDF},
  keywords  = {rank2},
  ranking   = {rank2},
}

@InCollection{Matula1969,
  author    = {David W. Matula},
  title     = {The cohesive strength of graphs},
  booktitle = {The Many Facets of Graph Theory},
  publisher = {Springer Berlin Heidelberg},
  year      = {1969},
  pages     = {215--221},
  comment   = {duality theorem between cuts and slicings, min man theorem between min cut and max connectivity},
  doi       = {10.1007/bfb0060120},
  file      = {:Matula1969_Chapter_TheCohesiveStrengthOfGraphs.pdf:PDF},
  keywords  = {rank2},
}

@Article{Matula1972,
  author    = {David W. Matula},
  title     = {k-Components, Clusters and Slicings in Graphs},
  journal   = {{SIAM} Journal on Applied Mathematics},
  year      = {1972},
  volume    = {22},
  number    = {3},
  pages     = {459--480},
  month     = {may},
  comment   = {not available as pdf},
  doi       = {10.1137/0122040},
  keywords  = {rank1},
  publisher = {Society for Industrial {\&} Applied Mathematics ({SIAM})},
}

@InCollection{Li2018,
  author    = {Yu-Feng Li and Liang-Hung Lu and Ying-Chao Hung},
  booktitle = {Advances in Intelligent Systems and Computing},
  publisher = {Springer International Publishing},
  title     = {{A New Clustering Algorithm Based on Graph Connectivity}},
  year      = {2018},
  month     = {nov},
  pages     = {442--454},
  abstract  = {A new clustering algorithm based on the concept of graph connectivity is introduced. The idea is to develop a meaningful graph representation for data, where each resulting sub-graph corresponds to a cluster with highly similar objects connected by edge. The proposed algorithm has a fairly strong theoretical basis that supports its originality and computational efficiency. Further, some useful guidelines are provided so that the algorithm can be tuned to optimize the well-designed quality indices. Numerical evidences show that the proposed algorithm can provide a very good clustering accuracy for a number of benchmark data and has a relatively low computational complexity compared to
some sophisticated clustering methods.},
  comment   = {only about using graphs to cluster data points, not to do anything dynamic},
  doi       = {10.1007/978-3-030-01174-1_33},
  file      = {:Li2018 - A New Clustering Algorithm Based on Graph Connectivity.pdf:PDF},
  keywords  = {clustering, graph theory, time complexity, rank1},
  ranking   = {rank1},
}

@InCollection{Matula1977,
  author    = {David W. Matula},
  title     = {Graph Theoretic Techniques for Cluster Analysis Algorithms},
  booktitle = {Classification and Clustering},
  publisher = {Elsevier},
  year      = {1977},
  pages     = {95--129},
  comment   = {not available as pdf (ScienceDirect)},
  doi       = {10.1016/b978-0-12-714250-0.50009-7},
  keywords  = {rank1},
}

@InProceedings{Matula1987,
  author    = {David W. Matula},
  title     = {Determining edge connectivity in 0(nm)},
  booktitle = {28th Annual Symposium on Foundations of Computer Science (sfcs 1987)},
  year      = {1987},
  month     = {oct},
  publisher = {{IEEE}},
  comment   = {subgraph with largest edge connectivity (unweighted) in O(n^2 m), determining edge connectivity in O(nm)},
  doi       = {10.1109/sfcs.1987.19},
  file      = {:Matula1987 - Determining Edge Connectivity in 0(nm).pdf:PDF},
  keywords  = {rank2},
}

@InProceedings{Holm1998,
  author    = {Jacob Holm and Kristian de Lichtenberg and Mikkel Thorup},
  title     = {Poly-logarithmic deterministic fully-dynamic algorithms for connectivity, minimum spanning tree, 2-edge, and biconnectivity},
  booktitle = {Proceedings of the thirtieth annual {ACM} symposium on Theory of computing - {STOC} {\textquotesingle}98},
  year      = {1998},
  publisher = {{ACM} Press},
  doi       = {10.1145/276698.276715},
  file      = {:Holm1998 - Poly Logarithmic Deterministic Fully Dynamic Algorithms for Connectivity, Minimum Spanning Tree, 2 Edge, and Biconnectivity.pdf:PDF},
}

@Article{Banerjee1991,
  author    = {Saibal Banerjee},
  title     = {An optimal algorithm to find the degrees of connectedness in an undirected edge-weighted graph},
  journal   = {Pattern Recognition Letters},
  year      = {1991},
  volume    = {12},
  number    = {7},
  pages     = {421--424},
  month     = {jul},
  doi       = {10.1016/0167-8655(91)90316-e},
  file      = {:Banerjee1991 - An Optimal Algorithm to Find the Degrees of Connectedness in an Undirected Edge Weighted Graph.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Sawlani2019,
  author      = {Saurabh Sawlani and Junxing Wang},
  title       = {{N}ear-{O}ptimal {F}ully {D}ynamic {D}ensest {S}ubgraph},
  journal     = {no idea},
  year        = {2019},
  abstract    = {We give the first fully dynamic algorithm which maintains a $(1+\epsilon)$-approximate densest subgraph in worst-case time $\text{poly}(\log n, \epsilon^{-1})$ per update with high probability. Dense subgraph discovery is an important primitive for many real-world applications such as community detection, link spam detection, distance query indexing, and computational biology. Our result improves upon the previous best approximation factor of $(4+\epsilon)$ for fully dynamic densest subgraph obtained by [Bhattacharya-Henzinger-Nanongkai-Tsourakakis, STOC`15]. Our algorithm combines the uniform sparsification technique used in [Mitzenmacher-Pachocki-Peng-Tsourakakis-Xu, KDD`15] and [McGregor-Tench-Vorotnikova-Vu, MFCS`15] along with an augmenting path-like dual adjustment technique to maintain an approximate solution efficiently.},
  comment     = {approach via dual: assign edge to endpoints as some load and minimize maximum vertex load,
very complicated, many data structures are maintained},
  date        = {2019-07-05},
  eprint      = {http://arxiv.org/abs/1907.03037v1},
  eprintclass = {cs.DS},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1907.03037v1:URL;:Sawlani2019-Near-Optimal Fully Dynamic Densest Subgraph.pdf:PDF},
  keywords    = {cs.DS, rank3},
}

@InCollection{Charikar2000,
  author    = {Moses Charikar},
  title     = {{G}reedy {A}pproximation {A}lgorithms for {F}inding {D}ense {C}omponents in a {G}raph},
  booktitle = {Approximation Algorithms for Combinatorial Optimization},
  publisher = {Springer Berlin Heidelberg},
  year      = {2000},
  pages     = {84--95},
  doi       = {10.1007/3-540-44436-x_10},
}

@InProceedings{Zhou2012,
  author    = {Rui Zhou and Chengfei Liu and Jeffrey Xu Yu and Weifa Liang and Baichen Chen and Jianxin Li},
  title     = {Finding maximal k-edge-connected subgraphs from a large graph},
  booktitle = {Proceedings of the 15th International Conference on Extending Database Technology - {EDBT} {\textquotesingle}12},
  year      = {2012},
  publisher = {{ACM} Press},
  abstract  = {In this paper, we study how to find maximal k-edge-connected subgraphs from a large graph. k-edge-connected subgraphs can be used to capture closely related vertices, and finding such vertex clusters is interesting in many applications, e.g., social network analysis, bioinformatics, web link research. Compared with other explicit structures for modeling vertex clusters, such as quasi-clique, k-core, which only set the requirement on vertex degrees, k-edge-connected subgraph further requires high connectivity within a subgraph (a stronger requirement), and hence defines a more closely related vertex cluster. To find maximal k-edge-connected subgraphs from a graph,
a basic approach is to repeatedly apply minimum cut algorithm to the connected components of the input graph until all connected components are k-connected. However, the basic approach is very expensive if the input graph is large. To tackle the problem, we propose three major techniques: vertex reduction, edge reduction and cut pruning. These speed-up techniques are applied on top of the basic approach. We conduct extensive experiments and show that
the speed-up techniques are very effective.},
  comment   = {cut-based approach to computing maximal k-edge-connected subgraphs, analysis and speedup-techniques},
  doi       = {10.1145/2247596.2247652},
  file      = {:Zhou2012 - Finding Maximal K Edge Connected Subgraphs from a Large Graph.pdf:PDF},
  keywords  = {rank5},
}

@InProceedings{Chang2013,
  author    = {Lijun Chang and Jeffrey Xu Yu and Lu Qin and Xuemin Lin and Chengfei Liu and Weifa Liang},
  booktitle = {Proceedings of the 2013 international conference on Management of data - {SIGMOD} {\textquotesingle}13},
  title     = {Efficiently computing k-edge connected components via graph decomposition},
  year      = {2013},
  publisher = {{ACM} Press},
  abstract  = {Efficiently computing k-edge connected components in a large graph, G = (V, E), where V is the vertex set and E is the edge set, is a long standing research problem. It is not only fundamental in graph analysis but also crucial in graph search optimization algorithms. Consider existing techniques for computing k-edge connected components are quite time consuming and are unlikely to be scalable for large scale graphs, in this paper we firstly propose a novel graph decomposition paradigm to iteratively decompose a graph G for computing its k-edge connected components such that the number of drilling-down iterations h is bounded by the “depth” of the k-edge connected components nested together to form G, where h usually is a small integer in practice. Secondly, we devise a novel, efficient threshold-based graph decomposition algorithm, with time complexity O(l × |E|), to decompose a graph G at each iteration, where l usually is a small integer with l ≪ |V|. As a result, our algorithm for computing k-edge connected components significantly improves the time complexity of an existing state-of-the-art technique from O(|V|2|E| + |V|3 log |V|) to O(h× l × |E|). Finally, we conduct extensive performance studies on large real and synthetic graphs. The performance studies demonstrate that our techniques significantly outperform the state-of-the-art solution by several or-
ders of magnitude.},
  comment   = {decomposition based k-edge connected components: based on the value of an s-t cut (compute via maximum adjacency search), s and t are merged if the value is >=k or cut otw.
uses a partition graph

running times: 
-threshold-based graph decomposition algorithm with time complexity O(l ×|E|) with a small integer l (usually l ≪ |V|)
-O(h × l × |E|), where l and h are usually bounded by a small constant in all the real and synthetic graphs},
  doi       = {10.1145/2463676.2465323},
  file      = {:Chang2013 - Efficiently Computing K Edge Connected Components Via Graph Decomposition.pdf:PDF},
  keywords  = {k-edge connected components; graph decomposition; minimum cut, rank5},
  ranking   = {rank5},
}

@InProceedings{Akiba2013,
  author    = {Takuya Akiba and Yoichi Iwata and Yuichi Yoshida},
  title     = {Linear-time enumeration of maximal K-edge-connected subgraphs in large networks by random contraction},
  booktitle = {Proceedings of the 22nd {ACM} international conference on Conference on information {\&} knowledge management - {CIKM} {\textquotesingle}13},
  year      = {2013},
  publisher = {{ACM} Press},
  abstract  = {Capturing sets of closely related vertices from large networks is an essential task in many applications such as social network analysis, bioinformatics, and web link research. Decomposing a graph into k-core components is a standard and efficient method for this task, but obtained clusters might not be well-connected. The idea of using maximal k-edgeconnected subgraphs was recently proposed to address this issue. Although we can obtain better clusters with this idea, the state-of-the-art method is not efficient enough to process large networks with millions of vertices. In this paper, we propose a new method to decompose
a graph into maximal k-edge-connected components, based on random contraction of edges. Our method is simple to implement but improves performance drastically. We experimentally show that our method can successfully decompose large networks and it is thousands times faster than the previous method. Also, we theoretically explain why our method is efficient in practice. To see the importance of maximal k-edge-connected subgraphs, we also conduct experiments using real-world networks to show that many k-core components have small edge-connectivity and they can be decomposed into a lot of maximal k-edge-connected
subgraphs.},
  comment   = {fast approach to finding maximal k-connected subgraphs via deleting nodes of small degree and contracting edges.
applies this basic approach repeatedly on found subgraphs to obtain good results
proofed running time: =(m log n)
argued running time in real scenarios: O(m)},
  doi       = {10.1145/2505515.2505751},
  file      = {:Akiba2013 - Linear Time Enumeration of Maximal K Edge Connected Subgraphs in Large Networks by Random Contraction.pdf:PDF},
  keywords  = {Graphs, vertex clusters, cohesive subgraphs, connectivity, maximal k-edge-connected subgraph, random contraction, rank5},
}

@Article{Aksu2014,
  author    = {Hidayet Aksu and Mustafa Canim and Yuan-Chi Chang and Ibrahim Korpeoglu and ozgur Ulusoy},
  title     = {{D}istributed k-{C}ore {V}iew {M}aterialization and {M}aintenance for {L}arge {D}ynamic {G}raphs},
  journal   = {{IEEE} Transactions on Knowledge and Data Engineering},
  year      = {2014},
  volume    = {26},
  number    = {10},
  pages     = {2439--2452},
  month     = {oct},
  doi       = {10.1109/tkde.2013.2297918},
  file      = {:Aksu2014 - Distributed k-Core View Materialization and Maintenance for Large Dynamic Graphs.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Veremyev2014,
  author    = {Alexander Veremyev and Oleg A. Prokopyev and Vladimir Boginski and Eduardo L. Pasiliao},
  title     = {Finding maximum subgraphs with relatively large vertex connectivity},
  journal   = {European Journal of Operational Research},
  year      = {2014},
  volume    = {239},
  number    = {2},
  pages     = {349--362},
  month     = {dec},
  comment   = {only vertex connectivity, probably not interesting},
  doi       = {10.1016/j.ejor.2014.05.041},
  keywords  = {rank2},
  publisher = {Elsevier {BV}},
}

@Article{Stoer1997,
  author    = {Mechthild Stoer and Frank Wagner},
  title     = {A simple min-cut algorithm},
  journal   = {Journal of the {ACM}},
  year      = {1997},
  volume    = {44},
  number    = {4},
  pages     = {585--591},
  month     = {jul},
  doi       = {10.1145/263867.263872},
  file      = {:Stoer1997 - A Simple Min Cut Algorithm.pdf:PDF},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Article{Avin2019,
  author      = {Chen Avin and Manya Ghobadi and Chen Griner and Stefan Schmid},
  journal     = {arXiv:1905.08339v1},
  title       = {{Measuring the Complexity of Packet Traces}},
  year        = {2019},
  abstract    = {This paper studies the structure of several real-world traces (including Facebook, High-Performance Computing, Machine Learning, and simulation generated traces) and presents a systematic approach to quantify and compare the structure of packet traces based on the entropy contained in the trace file. Insights into the structure of packet traces can lead to improved network algorithms that are optimized toward specific traffic patterns. We then present a methodology to quantify the temporal and non-temporal components of entropy contained in a packet trace, called the trace complexity, using randomization and compression. We show that trace complexity provides unique insights into the characteristics of various applications and argue that there is a need for traffic generation models that preserve the intrinsic structure of empirically measured application traces. We then propose a traffic generator model that is able to produce a synthetic trace that matches the complexity level of its corresponding real-world trace.},
  date        = {2019-05-20},
  eprint      = {http://arxiv.org/abs/1905.08339v1},
  eprintclass = {cs.NI},
  eprinttype  = {arXiv},
  file        = {:Avin2019 - Measuring the Complexity of Packet Traces.pdf:PDF},
  keywords    = {cs.NI, C.2.3; C.4},
}

@Article{Avin2015a,
  author      = {Chen Avin and Marcin Bienkowski and Andreas Loukas and Maciej Pacut and Stefan Schmid},
  journal     = {arXiv preprint arXiv:1511.02074v5},
  title       = {{D}ynamic {B}alanced {G}raph {P}artitioning},
  abstract    = {This paper initiates the study of the classic balanced graph partitioning problem from an online perspective: Given an arbitrary sequence of pairwise communication requests between $n$ nodes, with patterns that may change over time, the objective is to service these requests efficiently by partitioning the nodes into $\ell$ clusters, each of size $k$, such that frequently communicating nodes are located in the same cluster. The partitioning can be updated dynamically by migrating nodes between clusters. The goal is to devise online algorithms which jointly minimize the amount of inter-cluster communication and migration cost. The problem features interesting connections to other well-known online problems. For example, scenarios with $\ell=2$ generalize online paging, and scenarios with $k=2$ constitute a novel online variant of maximum matching. We present several lower bounds and algorithms for settings both with and without cluster-size augmentation. In particular, we prove that any deterministic online algorithm has a competitive ratio of at least $k$, even with significant augmentation. Our main algorithmic contributions are an $O(k \log{k})$-competitive deterministic algorithm for the general setting with constant augmentation, and a constant competitive algorithm for the maximum matching variant.},
  date        = {2015-11-06},
  eprint      = {http://arxiv.org/abs/1511.02074v5},
  eprintclass = {cs.DS},
  eprinttype  = {arXiv},
  file        = {:Avin2015a - Dynamic Balanced Graph Partitioning.pdf:PDF},
  keywords    = {cs.DS},
}

@Article{Mogul2012,
  author    = {Jeffrey C. Mogul and Lucian Popa},
  title     = {What we talk about when we talk about cloud network performance},
  journal   = {{ACM} {SIGCOMM} Computer Communication Review},
  year      = {2012},
  volume    = {42},
  number    = {5},
  pages     = {44},
  month     = {sep},
  comment   = {read for overview of network communication in distributed systems},
  doi       = {10.1145/2378956.2378964},
  file      = {:Mogul2012 - What We Talk about When We Talk about Cloud Network Performance.pdf:PDF},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Article{Sleator1985,
  author    = {Daniel D. Sleator and Robert E. Tarjan},
  title     = {Amortized efficiency of list update and paging rules},
  journal   = {Communications of the {ACM}},
  year      = {1985},
  volume    = {28},
  number    = {2},
  pages     = {202--208},
  month     = {feb},
  doi       = {10.1145/2786.2793},
  file      = {:Sleator1985 - Amortized Efficiency of List Update and Paging Rules.pdf:PDF},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Article{Schreiber2018,
  author    = {Ethan L. Schreiber and Richard E. Korf and Michael D. Moffitt},
  title     = {Optimal Multi-Way Number Partitioning},
  journal   = {Journal of the {ACM}},
  year      = {2018},
  volume    = {65},
  number    = {4},
  pages     = {1--61},
  month     = {jul},
  comment   = {Used in workload re-embedding as source for k-way partitioning},
  doi       = {10.1145/3184400},
  file      = {:Schreiber2018 - Optimal Multi Way Number Partitioning.pdf:PDF},
  keywords  = {k-way partitioning},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Article{Avin2018,
  author    = {Chen Avin and Louis Cohen and Mahmoud Parham and Stefan Schmid},
  title     = {Competitive clustering of stochastic communication patterns on a ring},
  journal   = {Computing},
  year      = {2018},
  volume    = {101},
  number    = {9},
  pages     = {1369--1390},
  month     = {sep},
  doi       = {10.1007/s00607-018-0666-x},
  file      = {:Avin2018 - Competitive Clustering of Stochastic Communication Patterns on a Ring.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Andreev2006,
  author    = {Konstantin Andreev and Harald R\"acke},
  journal   = {Theory of Computing Systems},
  title     = {{B}alanced {G}raph {P}artitioning},
  year      = {2006},
  month     = {oct},
  number    = {6},
  pages     = {929--939},
  volume    = {39},
  doi       = {10.1007/s00224-006-1350-7},
  file      = {:Andreev2006 - Balanced Graph Partitioning.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Karypis1998,
  author    = {George Karypis and Vipin Kumar},
  title     = {A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs},
  journal   = {{SIAM} Journal on Scientific Computing},
  year      = {1998},
  volume    = {20},
  number    = {1},
  pages     = {359--392},
  month     = {jan},
  comment   = {for METIS PartGraphRecursive},
  doi       = {10.1137/s1064827595287997},
  publisher = {Society for Industrial {\&} Applied Mathematics ({SIAM})},
}

@Article{Karypis1998a,
  author    = {George Karypis and Vipin Kumar},
  title     = {Multilevelk-way Partitioning Scheme for Irregular Graphs},
  journal   = {Journal of Parallel and Distributed Computing},
  year      = {1998},
  volume    = {48},
  number    = {1},
  pages     = {96--129},
  month     = {jan},
  comment   = {for METIS PartGraphRecursive},
  doi       = {10.1006/jpdc.1997.1404},
  publisher = {Elsevier {BV}},
}

@Article{Karypis1999,
  author    = {George Karypis and Vipin Kumar},
  title     = {Parallel Multilevel series k-Way Partitioning Scheme for Irregular Graphs},
  journal   = {{SIAM} Review},
  year      = {1999},
  volume    = {41},
  number    = {2},
  pages     = {278--300},
  month     = {jan},
  comment   = {for ParMETIS V3_AdaptiveRepart},
  doi       = {10.1137/s0036144598334138},
  publisher = {Society for Industrial {\&} Applied Mathematics ({SIAM})},
}

@InProceedings{Schloegel2000,
  author    = {K. Schloegel and G. Karypis and V. Kumar},
  title     = {A Unified Algorithm for Load-balancing Adaptive Scientific Simulations},
  booktitle = {{ACM}/{IEEE} {SC} 2000 Conference ({SC}{\textquotesingle}00)},
  year      = {2000},
  publisher = {{IEEE}},
  comment   = {for ParMETIS V3_AdaptiveRepart},
  doi       = {10.1109/sc.2000.10035},
}

@Article{Schloegel1997,
  author    = {Kirk Schloegel and George Karypis and Vipin Kumar},
  title     = {Multilevel Diffusion Schemes for Repartitioning of Adaptive Meshes},
  journal   = {Journal of Parallel and Distributed Computing},
  year      = {1997},
  volume    = {47},
  number    = {2},
  pages     = {109--124},
  month     = {dec},
  comment   = {for ParMETIS V3_AdaptiveRepart},
  doi       = {10.1006/jpdc.1997.1410},
  publisher = {Elsevier {BV}},
}

@InCollection{Epstein2011,
  author    = {Leah Epstein and Csan{\'{a}}d Imreh and Asaf Levin and Judit Nagy-György},
  title     = {On Variants of File Caching},
  booktitle = {Automata, Languages and Programming},
  publisher = {Springer Berlin Heidelberg},
  year      = {2011},
  pages     = {195--206},
  comment   = {for showing the importance of efficient distribution of data in areas where network traffic may be high},
  doi       = {10.1007/978-3-642-22006-7_17},
  file      = {:Epstein2011_Chapter_OnVariantsOfFileCaching.pdf:PDF},
}

@Article{Fiat2002,
  author       = {Amos Fiat and Richard Karp and Mike Luby and Lyle McGeoch and Daniel Sleator and Neal E. Young},
  journal      = {arXiv preprint cs/0205038},
  title        = {{C}ompetitive {P}aging {A}lgorithms},
  year         = {2002},
  abstract     = {The paging problem is that of deciding which pages to keep in a memory of k pages in order to minimize the number of page faults. This paper introduces the marking algorithm, a simple randomized on-line algorithm for the paging problem, and gives a proof that its performance guarantee (competitive ratio) is O(log k). In contrast, no deterministic on-line algorithm can have a performance guarantee better than k.},
  date         = {2002-05-18},
  doi          = {10.1016/0196-6774(91)90041-V},
  eprint       = {cs/0205038v1},
  eprintclass  = {cs.DS},
  eprinttype   = {arXiv},
  file         = {:http\://arxiv.org/pdf/cs/0205038v1:PDF;:Fiat2002 - Competitive Paging Algorithms.pdf:PDF},
  journaltitle = {Journal of Algorithms 12:685-699 (1991)},
  keywords     = {cs.DS, cs.NI, F.2.0; F.1.2; C.0},
}

@InProceedings{Ghobadi2016,
  author    = {Monia Ghobadi and Daniel Kilper and Ratul Mahajan and Amar Phanishayee and Nikhil Devanur and Janardhan Kulkarni and Gireeja Ranade and Pierre-Alexandre Blanche and Houman Rastegarfar and Madeleine Glick},
  booktitle = {Proceedings of the 2016 conference on {ACM} {SIGCOMM} 2016 Conference - {SIGCOMM} {\textquotesingle}16},
  title     = {{ProjecToR: Agile Reconfigurable Data Center Interconnect}},
  year      = {2016},
  publisher = {{ACM} Press},
  doi       = {10.1145/2934872.2934911},
  file      = {:Ghobadi2016 - ProjecToR_ Agile Reconfigurable Data Center Interconnect.pdf:PDF},
}

@InCollection{Avin2016,
  author    = {Chen Avin and Andreas Loukas and Maciej Pacut and Stefan Schmid},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer Berlin Heidelberg},
  title     = {{Online Balanced Repartitioning}},
  year      = {2016},
  pages     = {243--256},
  doi       = {10.1007/978-3-662-53426-7_18},
}

@InProceedings{Hamedazimi2014,
  author    = {Navid Hamedazimi and Zafar Qazi and Himanshu Gupta and Vyas Sekar and Samir R. Das and Jon P. Longtin and Himanshu Shah and Ashish Tanwer},
  booktitle = {Proceedings of the 2014 {ACM} conference on {SIGCOMM} - {SIGCOMM} {\textquotesingle}14},
  title     = {{FireFly}},
  year      = {2014},
  publisher = {{ACM} Press},
  doi       = {10.1145/2619239.2626328},
}

@Article{Epstein2014,
  author    = {Leah Epstein and Hanan Zebedat-Haider},
  journal   = {Theory of Computing Systems},
  title     = {Rent or Buy Problems with a Fixed Time Horizon},
  year      = {2014},
  month     = {jun},
  number    = {2},
  pages     = {309--329},
  volume    = {56},
  doi       = {10.1007/s00224-014-9552-x},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Walshaw2000,
  author    = {C. Walshaw and M. Cross},
  journal   = {{SIAM} Journal on Scientific Computing},
  title     = {Mesh Partitioning: A Multilevel Balancing and Refinement Algorithm},
  year      = {2000},
  month     = {jan},
  number    = {1},
  pages     = {63--80},
  volume    = {22},
  doi       = {10.1137/s1064827598337373},
  publisher = {Society for Industrial {\&} Applied Mathematics ({SIAM})},
}

@Article{walshaw2007jostle,
  author  = {Walshaw, Chris and Cross, Mark},
  journal = {Mesh partitioning techniques and domain decomposition techniques},
  title   = {{JOSTLE: parallel multilevel graph-partitioning software--an overview}},
  year    = {2007},
  pages   = {27--58},
}

@Comment{jabref-meta: databaseType:bibtex;}
